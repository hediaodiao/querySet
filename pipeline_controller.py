#!/usr/bin/env python3
"""
ä¸‰é˜¶æ®µæµæ°´çº¿ä¸»æ§åˆ¶å™¨
å®ç°å®Œæ•´çš„ "æ–‡ä»¶åè§„åˆ™åˆç­› â†’ æ¨¡å‹è§†è§‰æ ¡éªŒ â†’ äººå·¥æœ€ç»ˆå®¡æ ¸" æµç¨‹
"""

import subprocess
import sys
import os
import json
from pathlib import Path


def run_command(cmd, desc="æ‰§è¡Œå‘½ä»¤"):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print(f"\nğŸ” {desc}")
    print(f"   å‘½ä»¤: {' '.join(cmd) if isinstance(cmd, list) else cmd}")
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"   âœ… {desc} å®Œæˆ")
        return True, result.stdout
    except subprocess.CalledProcessError as e:
        print(f"   âŒ {desc} å¤±è´¥")
        print(f"   é”™è¯¯: {e.stderr}")
        return False, e.stderr


def check_prerequisites():
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    print("ğŸ“‹ æ£€æŸ¥å‰ç½®æ¡ä»¶...")
    
    # æ£€æŸ¥å¿…è¦çš„PythonåŒ…
    required_packages = ['torch', 'torchvision', 'PIL', 'sklearn', 'numpy']
    missing_packages = []
    
    for pkg in required_packages:
        try:
            if pkg == 'PIL':
                import PIL
            elif pkg == 'sklearn':
                import sklearn
            elif pkg == 'torch':
                import torch
            elif pkg == 'torchvision':
                import torchvision
            elif pkg == 'numpy':
                import numpy
        except ImportError:
            missing_packages.append(pkg)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘å¿…è¦åŒ…: {missing_packages}")
        print("è¯·è¿è¡Œ: pip install torch torchvision pillow scikit-learn numpy")
        return False
    
    # æ£€æŸ¥å›¾ç‰‡ç›®å½•
    if not os.path.exists("./Pic"):
        print("âŒ æœªæ‰¾åˆ° ./Pic ç›®å½•")
        return False
    
    print("âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡")
    return True


def stage_1_filename_grouping():
    """ç¬¬ä¸€é˜¶æ®µï¼šæ–‡ä»¶åè§„åˆ™åˆ†ç»„"""
    print("\n" + "="*60)
    print("ğŸš€ ç¬¬ä¸€é˜¶æ®µï¼šæ–‡ä»¶åè§„åˆ™åˆ†ç»„")
    print("="*60)
    
    if os.path.exists("./similarity_annotations.json"):
        print("âœ… æ£€æµ‹åˆ°å·²å­˜åœ¨çš„åˆ†ç»„ç»“æœæ–‡ä»¶")
        with open("./similarity_annotations.json", 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"   å·²æœ‰ {len(data)} ä¸ªåˆ†ç»„æ¡ç›®")
        return True
    
    print("âš ï¸ æœªæ‰¾åˆ°åˆ†ç»„ç»“æœæ–‡ä»¶ï¼Œéœ€è¦è¿è¡Œ main2.py")
    print("ğŸ’¡ æ³¨æ„: è¯·ç¡®ä¿æ‚¨æœ‰ main2.py æ–‡ä»¶æ¥è¿›è¡Œæ–‡ä»¶åè§„åˆ™åˆ†ç»„")
    
    # å¦‚æœæ²¡æœ‰main2.pyï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬
    if not os.path.exists("./main2.py"):
        print("ğŸ’¡ åˆ›å»ºç®€åŒ–ç‰ˆæ–‡ä»¶ååˆ†ç»„è„šæœ¬...")
        create_simple_grouping_script()
    
    success, _ = run_command(["python", "main2.py"], "è¿è¡Œæ–‡ä»¶ååˆ†ç»„")
    return success


def create_simple_grouping_script():
    """åˆ›å»ºç®€åŒ–ç‰ˆçš„æ–‡ä»¶ååˆ†ç»„è„šæœ¬"""
    script_content = '''
#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆæ–‡ä»¶ååˆ†ç»„è„šæœ¬
æ ¹æ®æ–‡ä»¶åå‰8ä½æ•°å­—è¿›è¡Œåˆ†ç»„
"""

import os
import json
import re
from collections import defaultdict


def group_images_by_filename(pic_dir="./Pic"):
    """æ ¹æ®æ–‡ä»¶åå‰8ä½æ•°å­—å¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç»„"""
    groups = defaultdict(list)
    
    # éå†æ‰€æœ‰å­ç›®å½•
    for root, dirs, files in os.walk(pic_dir):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):
                # æå–æ–‡ä»¶åä¸­çš„æ•°å­—å‰ç¼€ï¼ˆå‰8ä½ï¼‰
                match = re.search(r'(\\d{8,})', file)
                if match:
                    # å–å‰8ä½ä½œä¸ºäº§å“ID
                    product_id = match.group(1)[:8]
                    # è·å–ç›¸å¯¹è·¯å¾„
                    rel_path = os.path.relpath(os.path.join(root, file), pic_dir)
                    rel_path = rel_path.replace("\\\\", "/")  # ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦
                    groups[product_id].append(rel_path)
    
    # è½¬æ¢ä¸ºæ‰€éœ€çš„æ ¼å¼
    similarity_annotations = []
    for product_id, image_list in groups.items():
        if len(image_list) >= 1:  # è‡³å°‘æœ‰ä¸€å¼ å›¾ç‰‡æ‰åˆ›å»ºæ¡ç›®
            # å°†ç¬¬ä¸€ä¸ªå›¾ç‰‡ä½œä¸ºquery_imageï¼Œå…¶ä½™ä½œä¸ºrelevant_images
            query_image = image_list[0]
            relevant_images = image_list[1:] if len(image_list) > 1 else []
            
            # ä»è·¯å¾„ä¸­æå–ç±»åˆ«ä¿¡æ¯
            category = os.path.basename(os.path.dirname(query_image)) if os.path.dirname(query_image) else "unknown"
            
            similarity_annotations.append({
                "query_image": query_image,
                "relevant_images": relevant_images,
                "category": category,
                "product_id": product_id
            })
    
    return similarity_annotations


def main():
    print("å¼€å§‹æŒ‰æ–‡ä»¶åè§„åˆ™åˆ†ç»„...")
    annotations = group_images_by_filename()
    
    print(f"åˆ†ç»„å®Œæˆï¼Œå…±ç”Ÿæˆ {len(annotations)} ä¸ªåˆ†ç»„")
    
    # ä¿å­˜ç»“æœ
    with open("./similarity_annotations.json", 'w', encoding='utf-8') as f:
        json.dump(annotations, f, indent=2, ensure_ascii=False)
    
    print("ç»“æœå·²ä¿å­˜è‡³ similarity_annotations.json")
    

if __name__ == "__main__":
    main()
'''
    
    with open("./main2.py", 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print("âœ… ç®€åŒ–ç‰ˆåˆ†ç»„è„šæœ¬åˆ›å»ºå®Œæˆ")


def stage_2_model_verification():
    """ç¬¬äºŒé˜¶æ®µï¼šæ¨¡å‹è§†è§‰æ ¡éªŒ"""
    print("\n" + "="*60)
    print("ğŸ” ç¬¬äºŒé˜¶æ®µï¼šæ¨¡å‹è§†è§‰æ ¡éªŒ")
    print("="*60)
    
    if not os.path.exists("./similarity_annotations.json"):
        print("âŒ æœªæ‰¾åˆ°åŸºç¡€åˆ†ç»„æ–‡ä»¶ï¼Œæ— æ³•è¿›è¡Œè§†è§‰æ ¡éªŒ")
        return False
    
    success, _ = run_command(["python", "openclip_only_verification.py"], "è¿è¡Œæ¨¡å‹è§†è§‰æ ¡éªŒ")
    return success


def stage_3_manual_review():
    """ç¬¬ä¸‰é˜¶æ®µï¼šäººå·¥å®¡æ ¸"""
    print("\n" + "="*60)
    print("ğŸ‘¥ ç¬¬ä¸‰é˜¶æ®µï¼šäººå·¥å®¡æ ¸")
    print("="*60)
    
    # æ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š
    verification_report_exists = os.path.exists("./similarity_annotations_verification_report.json")
    merge_report_exists = os.path.exists("./similarity_annotations_review_report.json")
    
    if verification_report_exists or merge_report_exists:
        print("âœ… æ£€æµ‹åˆ°æ ¡éªŒæŠ¥å‘Šï¼Œå¯ä»¥å¼€å§‹äººå·¥å®¡æ ¸")
        print("\nğŸ’¡ è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¹‹ä¸€è¿›è¡Œå®¡æ ¸ï¼š")
        print("   python group_review_tool.py     # åŸºç¡€å®¡æ ¸")
        print("   python review_tool_optimized.py # ä¼˜åŒ–å®¡æ ¸ï¼ˆå¦‚æœ‰åˆå¹¶å»ºè®®ï¼‰")
        return True
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ ¡éªŒæŠ¥å‘Šï¼Œå°†ç›´æ¥ä½¿ç”¨åŸºç¡€åˆ†ç»„ç»“æœè¿›è¡Œå®¡æ ¸")
        if os.path.exists("./similarity_annotations.json"):
            print("âœ… åŸºç¡€åˆ†ç»„æ–‡ä»¶å­˜åœ¨ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå®¡æ ¸")
            return True
        else:
            print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨çš„åˆ†ç»„æ–‡ä»¶è¿›è¡Œå®¡æ ¸")
            return False


def generate_final_report():
    """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    print("="*60)
    
    report = {
        "pipeline_status": "completed",
        "stages_completed": [],
        "files_generated": [],
        "summary": {}
    }
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    files_to_check = [
        "similarity_annotations.json",
        "similarity_annotations_verification_report.json",
        "similarity_annotations_initial.json",
        "similarity_annotations_final.json",
        "similarity_annotations_review_report.json"
    ]
    
    for file in files_to_check:
        if os.path.exists(file):
            size = os.path.getsize(file)
            report["files_generated"].append({
                "name": file,
                "size_bytes": size,
                "exists": True
            })
            
            # å¦‚æœæ˜¯JSONæ–‡ä»¶ï¼Œå°è¯•åŠ è½½ç»Ÿè®¡ä¿¡æ¯
            if file.endswith('.json'):
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            report["summary"][file] = f"{len(data)} ä¸ªé¡¹ç›®"
                        elif isinstance(data, dict) and "verified_annotations" in data:
                            report["summary"][file] = f"{len(data['verified_annotations'])} ä¸ªéªŒè¯æ¡ç›®"
                except:
                    pass
        else:
            report["files_generated"].append({
                "name": file,
                "exists": False
            })
    
    # ä¿å­˜æŠ¥å‘Š
    with open("pipeline_report.json", 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("âœ… æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ: pipeline_report.json")
    
    # æ‰“å°æ‘˜è¦
    print("\nğŸ“‹ æµæ°´çº¿æ‘˜è¦:")
    for file_info in report["files_generated"]:
        status = "âœ…" if file_info["exists"] else "âŒ"
        print(f"   {status} {file_info['name']}")
        if file_info['name'] in report['summary']:
            print(f"      â””â”€ {report['summary'][file_info['name']]}")
    
    return True


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´æµæ°´çº¿"""
    print("ğŸ¨ å›¾ç‰‡åˆ†ç»„ä¸‰é˜¶æ®µæµæ°´çº¿")
    print("   é˜¶æ®µ1: æ–‡ä»¶åè§„åˆ™åˆç­›")
    print("   é˜¶æ®µ2: æ¨¡å‹è§†è§‰æ ¡éªŒ") 
    print("   é˜¶æ®µ3: äººå·¥æœ€ç»ˆå®¡æ ¸")
    print()
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not check_prerequisites():
        print("\nâŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡º")
        return
    
    # æ‰§è¡Œä¸‰ä¸ªé˜¶æ®µ
    stages_success = []
    
    # é˜¶æ®µ1ï¼šæ–‡ä»¶ååˆ†ç»„
    success = stage_1_filename_grouping()
    stages_success.append(("Stage 1 - Filename Grouping", success))
    
    if not success:
        print("\nâŒ ç¬¬ä¸€é˜¶æ®µå¤±è´¥ï¼Œæµæ°´çº¿ç»ˆæ­¢")
        return
    
    # é˜¶æ®µ2ï¼šæ¨¡å‹è§†è§‰æ ¡éªŒ
    success = stage_2_model_verification()
    stages_success.append(("Stage 2 - Model Verification", success))
    
    if not success:
        print("\nâš ï¸  ç¬¬äºŒé˜¶æ®µå¤±è´¥ï¼Œä½†ä»å¯è¿›è¡Œäººå·¥å®¡æ ¸")
    
    # é˜¶æ®µ3ï¼šäººå·¥å®¡æ ¸
    success = stage_3_manual_review()
    stages_success.append(("Stage 3 - Manual Review", success))
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    generate_final_report()
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ æµæ°´çº¿æ‰§è¡Œå®Œæˆ")
    print("="*60)
    
    for stage, success in stages_success:
        status = "âœ…" if success else "âŒ"
        print(f"   {status} {stage}")
    
    completed_count = sum(1 for _, success in stages_success if success)
    print(f"\nğŸ“ˆ å®Œæˆç‡: {completed_count}/{len(stages_success)} é˜¶æ®µ")


if __name__ == "__main__":
    main()